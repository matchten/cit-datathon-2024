{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f6c56e-0a8e-445d-bcfd-abcd82140c73",
   "metadata": {},
   "source": [
    "# Costs and Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15ce5a08-bf39-4b7b-804d-47e2d6563517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATHNAME = \"./datasets/\"\n",
    "P_VALUE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0848a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sugar_coffee_df = pd.read_csv(\"./datasets/all_commodities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313e0b1-2888-4ffc-b579-17a9b29209d3",
   "metadata": {},
   "source": [
    "# Sugar and Coffee Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59c3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c735ac4d",
   "metadata": {},
   "source": [
    "# Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634e5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data as done in EDA\n",
    "\n",
    "Midwest = ['Illinois', 'Indiana', 'Iowa', 'Kansas', 'Michigan', 'Minnesota', 'Missouri', 'Nebraska', 'North Dakota', 'Ohio', 'South Dakota', 'Wisconsin']\n",
    "South = ['Delaware', 'Florida', 'Georgia', 'Maryland', 'North Carolina', 'South Carolina', 'Virginia', 'Washington D.C.', 'West Virginia', 'Alabama', 'Kentucky', 'Mississippi', 'Tennessee', 'Arkansas', 'Louisiana', 'Oklahoma', 'Texas']\n",
    "West = ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'New Mexico', 'Utah', 'Wyoming', 'Alaska', 'California', 'Hawaii', 'Oregon', 'Washington']\n",
    "East = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', 'Vermont', 'New Jersey', 'New York', 'Pennsylvania']\n",
    "\n",
    "data_path = \"./datasets/acs_5yr_est_selected_economic_characteristics_2010-2022.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.replace('(X)', np.nan)\n",
    "# Convert the Estimate column to float\n",
    "# df = df.dropna(subset=['Estimate'])\n",
    "df['Estimate'] = df['Estimate'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Strip leading invisible characters from Label column\n",
    "df['Label (Grouping)'] = df['Label (Grouping)'].str.lstrip()\n",
    "\n",
    "# Create sub-dataframes for each region and analyze them\n",
    "regions = {\n",
    "    'Midwest': Midwest,\n",
    "    'South': South,\n",
    "    'West': West,\n",
    "    'East': East\n",
    "}\n",
    "\n",
    "all_regions_df = pd.DataFrame()\n",
    "\n",
    "for region_name, states in regions.items():\n",
    "    \n",
    "    # Create sub-dataframe for the region\n",
    "    region_df = df[df['State'].isin(states)]\n",
    "    \n",
    "    # Filter for median household income and Population 16 years and over in labor force\n",
    "    region_df = region_df[\n",
    "        ((region_df['Label (Grouping)'].str.contains('Percent Unemployed')) & (region_df['Category'] == 'EMPLOYMENT STATUS')) |\n",
    "        ((region_df['Label (Grouping)'].str.contains('Unemployment Rate')) & (region_df['Category'] == 'EMPLOYMENT STATUS')) |\n",
    "        ((region_df['Label (Grouping)'] == 'Median household income (dollars)')) |\n",
    "        ((region_df['Label (Grouping)'].str.contains('All people')) & (region_df['Category'] == 'PERCENTAGE OF FAMILIES AND PEOPLE WHOSE INCOME IN THE PAST 12 MONTHS IS BELOW THE POVERTY LEVEL'))\n",
    "    ]\n",
    "    region_df['Percent'] = region_df['Percent'].str.rstrip('%').astype('float')\n",
    "\n",
    "    # Split region_df into three different dataframes\n",
    "    unemployed_df = region_df[region_df['Label (Grouping)'].str.contains('Percent Unemployed') | region_df['Label (Grouping)'].str.contains('Unemployment Rate')]\n",
    "    income_df = region_df[region_df['Label (Grouping)'] == 'Median household income (dollars)']\n",
    "    poverty_df = region_df[region_df['Label (Grouping)'].str.contains('All people')]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    unemployed_df = unemployed_df.rename(columns={'Percent': 'Unemployment Rate'})\n",
    "    income_df = income_df.rename(columns={'Estimate': 'Median Household Income'})\n",
    "    poverty_df = poverty_df.rename(columns={'Percent': 'Poverty Rate'})\n",
    "\n",
    "    # Reassign region_df to include all three dataframes\n",
    "    region_df = pd.concat([unemployed_df, income_df, poverty_df])\n",
    "    \n",
    "    # Add Region column\n",
    "    region_df['Region'] = region_name\n",
    "    \n",
    "    # Append to all_regions_df\n",
    "    all_regions_df = pd.concat([all_regions_df, region_df], ignore_index=True)\n",
    "    \n",
    "all_regions_df.drop(['Percent', 'Estimate'], axis=1, inplace=True)\n",
    "\n",
    "health = pd.read_csv('datasets/Nutrition_Physical_Activity_and_Obesity_Data.csv')\n",
    "questions = [\n",
    "    'Percent of adults aged 18 years and older who have obesity',\n",
    "    'Percent of students in grades 9-12 who have obesity',\n",
    "    'Percent of adults who engage in no leisure-time physical activity',\n",
    "    'Percent of students in grades 9-12 who achieve 1 hour or more of moderate-and/or vigorous-intensity physical activity daily',\n",
    "    'Percent of adults who report consuming vegetables less than one time daily',\n",
    "    'Percent of students in grades 9-12 who consume vegetables less than 1 time daily'\n",
    "]\n",
    "health = health[health['Question'].isin(questions)]\n",
    "health.dropna(subset=['Data_Value'], inplace=True)\n",
    "\n",
    "for question in questions:\n",
    "    count = health[health['Question'] == question].shape[0]\n",
    "# Create dictionaries to store regional dataframes\n",
    "regional_dfs = {\n",
    "    'Midwest': pd.DataFrame(),\n",
    "    'South': pd.DataFrame(),\n",
    "    'West': pd.DataFrame(),\n",
    "    'East': pd.DataFrame()\n",
    "}\n",
    "\n",
    "# Function to determine region for a given state\n",
    "def get_region(state):\n",
    "    if state in Midwest:\n",
    "        return 'Midwest'\n",
    "    elif state in South:\n",
    "        return 'South'\n",
    "    elif state in West:\n",
    "        return 'West'\n",
    "    elif state in East:\n",
    "        return 'East'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Add a 'Region' column to the health dataframe\n",
    "health['Region'] = health['LocationDesc'].apply(get_region)\n",
    "\n",
    "# Filter and split the dataframe for each region\n",
    "for region in regional_dfs.keys():\n",
    "    regional_dfs[region] = health[health['Region'] == region][['YearStart', 'LocationDesc', 'Question', 'Data_Value']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f2e9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting columns: Index(['Region', 'State', 'Year', 'Adult Obesity Rate',\n",
      "       'Percent of adults who engage in no leisure-time physical activity',\n",
      "       'Percent of adults who report consuming vegetables less than one time daily',\n",
      "       'Percent of students in grades 9-12 who achieve 1 hour or more of moderate-and/or vigorous-intensity physical activity daily',\n",
      "       'Percent of students in grades 9-12 who consume vegetables less than 1 time daily',\n",
      "       'Student Obesity Rate'],\n",
      "      dtype='object')\n",
      "\n",
      "Correlations for Midwest:\n",
      "                         Poverty Rate  Median Household Income  \\\n",
      "Poverty Rate                 1.000000                -0.746489   \n",
      "Median Household Income     -0.746489                 1.000000   \n",
      "Unemployment Rate            0.751909                -0.538197   \n",
      "Adult Obesity Rate          -0.056126                 0.168695   \n",
      "Student Obesity Rate        -0.214825                 0.389219   \n",
      "\n",
      "                         Unemployment Rate  Adult Obesity Rate  \\\n",
      "Poverty Rate                      0.751909           -0.056126   \n",
      "Median Household Income          -0.538197            0.168695   \n",
      "Unemployment Rate                 1.000000           -0.113940   \n",
      "Adult Obesity Rate               -0.113940            1.000000   \n",
      "Student Obesity Rate             -0.299766            0.049708   \n",
      "\n",
      "                         Student Obesity Rate  \n",
      "Poverty Rate                        -0.214825  \n",
      "Median Household Income              0.389219  \n",
      "Unemployment Rate                   -0.299766  \n",
      "Adult Obesity Rate                   0.049708  \n",
      "Student Obesity Rate                 1.000000  \n",
      "\n",
      "Correlations for South:\n",
      "                         Poverty Rate  Median Household Income  \\\n",
      "Poverty Rate                 1.000000                -0.896168   \n",
      "Median Household Income     -0.896168                 1.000000   \n",
      "Unemployment Rate            0.513021                -0.585261   \n",
      "Adult Obesity Rate           0.152472                -0.091907   \n",
      "Student Obesity Rate         0.421194                -0.347551   \n",
      "\n",
      "                         Unemployment Rate  Adult Obesity Rate  \\\n",
      "Poverty Rate                      0.513021            0.152472   \n",
      "Median Household Income          -0.585261           -0.091907   \n",
      "Unemployment Rate                 1.000000           -0.233610   \n",
      "Adult Obesity Rate               -0.233610            1.000000   \n",
      "Student Obesity Rate             -0.254172            0.208596   \n",
      "\n",
      "                         Student Obesity Rate  \n",
      "Poverty Rate                         0.421194  \n",
      "Median Household Income             -0.347551  \n",
      "Unemployment Rate                   -0.254172  \n",
      "Adult Obesity Rate                   0.208596  \n",
      "Student Obesity Rate                 1.000000  \n",
      "\n",
      "Correlations for West:\n",
      "                         Poverty Rate  Median Household Income  \\\n",
      "Poverty Rate                 1.000000                -0.773142   \n",
      "Median Household Income     -0.773142                 1.000000   \n",
      "Unemployment Rate            0.575004                -0.453423   \n",
      "Adult Obesity Rate           0.099947                -0.040782   \n",
      "Student Obesity Rate         0.290577                -0.076134   \n",
      "\n",
      "                         Unemployment Rate  Adult Obesity Rate  \\\n",
      "Poverty Rate                      0.575004            0.099947   \n",
      "Median Household Income          -0.453423           -0.040782   \n",
      "Unemployment Rate                 1.000000           -0.044010   \n",
      "Adult Obesity Rate               -0.044010            1.000000   \n",
      "Student Obesity Rate              0.248339            0.134521   \n",
      "\n",
      "                         Student Obesity Rate  \n",
      "Poverty Rate                         0.290577  \n",
      "Median Household Income             -0.076134  \n",
      "Unemployment Rate                    0.248339  \n",
      "Adult Obesity Rate                   0.134521  \n",
      "Student Obesity Rate                 1.000000  \n",
      "\n",
      "Correlations for East:\n",
      "                         Poverty Rate  Median Household Income  \\\n",
      "Poverty Rate                 1.000000                -0.620992   \n",
      "Median Household Income     -0.620992                 1.000000   \n",
      "Unemployment Rate            0.378233                -0.286119   \n",
      "Adult Obesity Rate           0.082293                 0.022191   \n",
      "Student Obesity Rate         0.169980                -0.191193   \n",
      "\n",
      "                         Unemployment Rate  Adult Obesity Rate  \\\n",
      "Poverty Rate                      0.378233            0.082293   \n",
      "Median Household Income          -0.286119            0.022191   \n",
      "Unemployment Rate                 1.000000           -0.215940   \n",
      "Adult Obesity Rate               -0.215940            1.000000   \n",
      "Student Obesity Rate             -0.447036            0.154249   \n",
      "\n",
      "                         Student Obesity Rate  \n",
      "Poverty Rate                         0.169980  \n",
      "Median Household Income             -0.191193  \n",
      "Unemployment Rate                   -0.447036  \n",
      "Adult Obesity Rate                   0.154249  \n",
      "Student Obesity Rate                 1.000000  \n",
      "Heatmap for Midwest saved as correlation_heatmap_Midwest.png\n",
      "Heatmap for South saved as correlation_heatmap_South.png\n",
      "Heatmap for West saved as correlation_heatmap_West.png\n",
      "Heatmap for East saved as correlation_heatmap_East.png\n",
      "Heatmap for all regions combined saved as correlation_heatmap_all_regions.png\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the economic data\n",
    "economic_data = all_regions_df.pivot_table(\n",
    "    values=['Unemployment Rate', 'Median Household Income', 'Poverty Rate'],\n",
    "    index=['Region', 'State', 'Year'],\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Step 2: Prepare the health data\n",
    "health_data = pd.concat(regional_dfs.values())\n",
    "\n",
    "# Pivot table with correct column names\n",
    "health_data = health_data.pivot_table(\n",
    "    values='Data_Value',\n",
    "    index=['LocationDesc', 'YearStart'],\n",
    "    columns='Question',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "health_data.columns.name = None\n",
    "health_data = health_data.rename(columns={\n",
    "    'LocationDesc': 'State',\n",
    "    'YearStart': 'Year',\n",
    "    'Percent of adults aged 18 years and older who have obesity': 'Adult Obesity Rate',\n",
    "    'Percent of students in grades 9-12 who have obesity': 'Student Obesity Rate'\n",
    "})\n",
    "\n",
    "# Add the Region column back\n",
    "def get_region(state):\n",
    "    if state in Midwest:\n",
    "        return 'Midwest'\n",
    "    elif state in South:\n",
    "        return 'South'\n",
    "    elif state in West:\n",
    "        return 'West'\n",
    "    elif state in East:\n",
    "        return 'East'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "health_data['Region'] = health_data['State'].apply(get_region)\n",
    "\n",
    "# Reorder columns to put Region first\n",
    "cols = health_data.columns.tolist()\n",
    "cols = ['Region'] + [col for col in cols if col != 'Region']\n",
    "health_data = health_data[cols]\n",
    "\n",
    "# Print the resulting columns to verify\n",
    "print(\"Resulting columns:\", health_data.columns)\n",
    "\n",
    "# Step 3: Merge the datasets\n",
    "merged_data = pd.merge(\n",
    "    economic_data,\n",
    "    health_data[['Region', 'State', 'Year', 'Adult Obesity Rate', 'Student Obesity Rate']],\n",
    "    on=['Region', 'State', 'Year'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Step 4: Calculate correlations for each region\n",
    "correlations = {}\n",
    "\n",
    "for region in ['Midwest', 'South', 'West', 'East']:\n",
    "    region_data = merged_data[merged_data['Region'] == region]\n",
    "    \n",
    "    variables = ['Poverty Rate', 'Median Household Income', 'Unemployment Rate', 'Adult Obesity Rate', 'Student Obesity Rate']\n",
    "    region_correlations = region_data[variables].corr()\n",
    "    \n",
    "    correlations[region] = region_correlations\n",
    "\n",
    "# Print correlations for each region\n",
    "for region, corr_matrix in correlations.items():\n",
    "    print(f\"\\nCorrelations for {region}:\")\n",
    "    print(corr_matrix)\n",
    "\n",
    "correlation_matrix = merged_data[['Poverty Rate', 'Median Household Income', 'Unemployment Rate', 'Adult Obesity Rate', 'Student Obesity Rate']].corr()\n",
    "\n",
    "def create_and_save_heatmap(correlation_matrix, region, output_path):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', vmin=-1, vmax=1, center=0)\n",
    "    plt.title(f'Correlation Matrix for {region}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "    plt.show()\n",
    "\n",
    "# Create and save heatmaps for each region\n",
    "for region, corr_matrix in correlations.items():\n",
    "    output_path = f'correlation_heatmap_{region}.png'\n",
    "    create_and_save_heatmap(corr_matrix, region, output_path)\n",
    "    print(f\"Heatmap for {region} saved as {output_path}\")\n",
    "    print(corr_matrix)\n",
    "\n",
    "# If you want to create a single heatmap for all regions combined:\n",
    "all_regions_corr = merged_data[['Poverty Rate', 'Median Household Income', 'Unemployment Rate', 'Adult Obesity Rate', 'Student Obesity Rate']].corr()\n",
    "create_and_save_heatmap(all_regions_corr, 'All Regions', 'correlation_heatmap_all_regions.png')\n",
    "print(\"Heatmap for all regions combined saved as correlation_heatmap_all_regions.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
